{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differentiated Products Demand with Random Coefficients (BLP)\n",
    "---\n",
    "\n",
    "`2020-12-13`\n",
    "\n",
    "_Zhiyuan Chen_\n",
    "\n",
    "_Department of Trade Economics, Renmin Business School_\n",
    "\n",
    "__References__:\n",
    "\n",
    "* Berry, S., J. Levinsohn, and A. Pakes. (1995): “Automoile Price in Market Equilibrium,” Econometrica, 63, 841–90.\n",
    "* Nevo, A. (2000): “A Practitioner’s Guide to Estimation of Random-Coeffcients Logit Models of Demand,” Journal of economics & management strategy, 9, 513–48.\n",
    "\n",
    "The lecture is based on Nevo (2000) and the code is based on [Chirs Colon](https://chrisconlon.github.io/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "- [Model Setup](#Model-Setup)\n",
    "  - [Utility function](#Utility-function)\n",
    "  - [Data](#Data)\n",
    "  - [Indirect utility and market shares](#Indirect-utility-and-market-shares)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup \n",
    "### Utility function\n",
    "The aim of this model is to understand market-level substitution patterns\n",
    "through the lends of a discrete choice model with heterogeneous agents.\n",
    "We observe: \n",
    "\n",
    "* $t = 1,\\ldots,T$ *markets*, each containing a mass of consumers. For\n",
    "asymptotics, we will assume $T$ grows to infinity. These may be repeated\n",
    "observation of the same market over time (though we assume the model is\n",
    "static) or data from distinct markets where the same products compete\n",
    "(e.g., different cities or provinces). \n",
    "\n",
    "* A set of $J$ *products* which are offered in the markets. Each product\n",
    "has an average price in the market $p_{jt}$ and charachteristics which\n",
    "may vary by market $x_{jt}$. Not all products need to be offered in every\n",
    "market. (In fact, it may be helpful if there is variation in the choice\n",
    "set, assuming it is exogenous. \n",
    "\n",
    "We assume that consumers buy at most one product, and they do so to\n",
    "maximize their indirect utility conditional on purchase, where indirect\n",
    "utility of consumer $i$ in market $t$ of product $j$ is: \n",
    "\n",
    "$$ u_{ijt} = \\alpha_i(y_i - p_{jt}) + \\mathbf{x}_{jt} \\boldsymbol{\\beta}_i + \\xi_{jt} +\n",
    "\\varepsilon_{ijt} \\tag{1} $$ \n",
    "\n",
    "* $y_i$ is consumer i's income, so $(y_i - p_{jt})$ represents consumers\n",
    "i's expenditure on other goods (outside this market). The coefficient\n",
    "$\\alpha_i$ is consumer i's price sensitivity (so allows for\n",
    "non-homothetic preferences). \n",
    "* $ \\boldsymbol{\\beta}_i$ represents consumer i's taste for observable characteristic\n",
    "$\\mathbf{x}_{jt}$. \n",
    "* $\\xi_{jt}$ is an unobserved quality of product $j$ in market $t$ that\n",
    "is common to all consumers in $j$. It is important as it is potentially\n",
    "correlated with price. Importantly, it will be assumed to be\n",
    "uncorrellated with $x_{jt}$.\n",
    "* $\\varepsilon_{ijt}$ is a consumer-specific taste shock. Since it is\n",
    "specific to a consumer it is reasonable to assume that it is uncorellated\n",
    "with product charachteristics. \n",
    "\n",
    "### Data\n",
    "We aren't going to observe individual level data, only market level data,\n",
    "however we may assume that we learn the _distribution_ of consumer level\n",
    "charachteristics across markets. E.g., we can learn the income and age\n",
    "distribution by MSA. Therefore, we will assume that consumer tastes can\n",
    "be modeled according to distributional assumptions: \n",
    "\n",
    "$$ \\left( \\begin{array}{c} \\alpha_i \\\\ \\beta_i \\end{array} \\right) = \n",
    "    \\left( \\begin{array}{c} \\alpha \\\\ \\beta \\end{array} \\right) + \\Pi D_i\n",
    "    + \\Sigma \\nu_i $$\n",
    "\n",
    "* $D_i \\sim P_{Dt}(D)$ represents a draw from the distribution of\n",
    "demographics (income, race, family size) it is a $Z x 1$ vector. \n",
    "* $\\Pi$ is a $KxZ$ matrix that determines how demographic characteristics\n",
    "affect tastes on average (e.g., families with kids like sugary cereals\n",
    "more). \n",
    "* $\\nu_i \\sim P_\\nu(\\nu)$ represents a draw from the distribution of\n",
    "unobserved tastes. It is a $K x 1$ vector. The distribution $P_\\nu$ is\n",
    "assumed to be known (typicaly standard normal or log-normal). \n",
    "* $\\Sigma$ is a KxK vector that represents the Cholesky decomposition of\n",
    "the variance-covariance matrix of unobserved tastes. This has important\n",
    "implications for the estimation of substitution patterns. If $\\sigma_kk$\n",
    "is very large, it means products with a lot of charachteristic $k$ will\n",
    "be unlikely to subsitute to products with little $k$. Very often,\n",
    "$\\Sigma$ is a diagonal matrix to reduce the number of parameters to\n",
    "estimate. \n",
    "\n",
    "In addition to all the products that are purchased, we consider an\n",
    "outside good or ``no purchase'' option. This will simply be considered\n",
    "good 0: \n",
    "\n",
    "$$ u_{i0t} = \\alpha_i y_i + \\xi_{0t} + \\pi_0D_i + \\sigma_0 v_{i0} +\n",
    "\\varepsilon_{i0t} $$\n",
    "\n",
    "* The parameters $\\pi_0$ and $\\sigma_0$ allows for the outside good to have its own demographic and random\n",
    "effects however they are not identified seperately from an constant term\n",
    "on the inside goods, so we usually just set them to 0. (Not a huge deal\n",
    "since these are essentially the same thing). \n",
    "* Similarly, a $\\xi_{0t}$ is not identified unless we normalize one of\n",
    "the inside goods across markets. \n",
    "\n",
    "### Indirect Utility and Market Shares\n",
    "Given this structure, we can re-write indirect utilities in terms of\n",
    "linear and nonlinear parameters. Where linear parameters impact the mean\n",
    "utility of a product in market $j$ and non-linear parameters affect\n",
    "deviations from that mean. \n",
    "\n",
    "$$ u_{ijt} = \\alpha_i y_i + \\delta_{jt}(x_{jt}, p_{jt}, \\xi_{jt}; \\theta_1)\n",
    "   + \\mu_{ijt}(x_{jt}, p_{jt}, \\nu_{i}, D_i; \\theta_2) + \\varepsilon_{ijt} \\tag{2} $$  \n",
    "\n",
    "* $\\delta_{jt} = x_{jt} \\beta - \\alpha p_{jt} + \\xi_{jt}$ is the utility of the consumer with \"mean 0\" demographics and taste shocks.\n",
    "  $\\Theta_1 = (\\alpha, \\beta)$, the mean tastes. \n",
    "* $\\mu_{ijt} = [-p_{jt}, x_{jt}] ( \\Pi D_i + \\Sigma v_i )$ is this\n",
    "consumers i's deviation in utility for product j from mean, it is a function of $\\theta_2 = (\\Pi, \\Sigma)$.  \n",
    "\n",
    "Why are we doing this? Because we will exploit the result that, for a\n",
    "given distribution of heterogeneity, there will be a one-to-one mapping\n",
    "from observed shares $s_{\\cdot t}$ to mean utilities in the market\n",
    "$\\delta_{\\cdot t}$. That will allow us to create moments that are\n",
    "additively seperable in the structural error $\\xi_{jt}$. \n",
    "\n",
    "\n",
    "We observe market shares of each product in each market. To determine\n",
    "these, we need to integrate over all consumer-level charachteristics.\n",
    "Specifially define A_{jt} as the set of consumers who buy product $j$:\n",
    "\n",
    "$$ A_{jt}(x_{\\cdot t}, p_{\\cdot t}, \\delta_{\\cdot t}; \\theta_2) = \\left\n",
    "\\{ (D_i, \\nu_i, \\varepsilon_{i, \\cdot, t}) : \\forall \\ell \\in J, u_{ijt}\n",
    "\\geq u_{i \\ell t} \\right\\} $$\n",
    "\n",
    "* Notice we right this just as a function of delta and deviations from\n",
    "mean utility. That is one reason for this notation. \n",
    "* Now to calculate the predicted market shares, we just need to integrate over the distribution of tastes: \n",
    "\n",
    "$$ s_{jt} = \\int_{A_{jt}} dP_\\varepsilon(\\varepsilon) dP_\\nu(\\nu) dP_D(D) \\tag{3}$$\n",
    "\n",
    "## Distributional Assumptions and Substitution Pattern\n",
    "\n",
    "* We will assume that $\\varepsilon$ is a Type-I Extreme value shock, so\n",
    "it can be integrated out analytically. \n",
    "\n",
    "* Demographics are typically either simulated from a non-parametric\n",
    "distribution or from a parametric fit from data. \n",
    "\n",
    "* Taste shocks $\\nu_i$ will be numerically integrated from an assumed\n",
    "standardized distribution. \n",
    "\n",
    "The main thing this work buys us is flexible (and hopefully realistic)\n",
    "substitution patterns. What do we mean by this? Suppose we dropped\n",
    "demographics and taste heterogeneity from the model:\n",
    "\n",
    "$$ u_{ijt} = \\alpha_i y_i + \\delta_{jt}(x_{jt}, p_{jt}, \\xi_{jt}; \\theta_1)+ \\varepsilon_{ijt} $$  \n",
    "\n",
    "So the only thing\n",
    "allowing consumers to make different choices was $\\varepsilon_{ijt}$.\n",
    "Then we'd have the classic multinomial logit model: \n",
    "\n",
    "$$ s_{jt} = \\frac{ \\exp ( x_{jt} \\beta - \\alpha p_{jt} + \\xi_{jt} ) }{ 1 +\n",
    "\\sum_{\\ell \\in J} \\exp ( x_{\\ell t} \\beta - \\alpha p_{\\ell t} + \\xi_{\\ell\n",
    "t} ) } $$\n",
    "\n",
    "This involved no numerical integration, but also has the independence of\n",
    "irrelevant alternatives property, which implies substitution pattersn are essentially a function of shares. \n",
    "In fact the formula for elasticities are: \n",
    "\n",
    "$$ \\eta_{jkt} = \\frac{\\partial s_{jt} p_{kt}}{\\partial p_{kt} s_{jt}} =  \\left\\{ \\begin{array}{lr} -\\alpha p_{jt}(1-s_{jt}) & \\mbox{if } j = k \\\\ \n",
    "                                 \\alpha p_{kt} s_{kt} & \\mbox{if } j \\neq k  \\end{array} \\right. $$\n",
    "\n",
    "So all the work of determining price elasticities is done by a single\n",
    "parameter, $\\alpha$, for both own and cross-price substitution. This brings up two problems:\n",
    "\n",
    ">1. The lower the price, the lower the elasticity, implying a higher markup;\n",
    ">2. It restricts consumers to substitute towards other brands in proportion to market shares, regardless of chracteristics\n",
    "\n",
    "\n",
    "However,\n",
    "in the full model, we have a logit-type substitution pattern at the\n",
    "consumer level, but must integrarte over consumers to get the market\n",
    "level elasticities the firms care about: \n",
    "\n",
    "$$ \\eta_{jkt} = \\frac{\\partial s_{jt} p_{kt}}{\\partial p_{kt} s_{jt}} =  \\left\\{ \\begin{array}{lr} - \\frac{p_{jt}}{s_{jt}} \\int \\alpha_i s_{ijt}(1-s_{ijt}) dP_D(D) dP_\\nu(\\nu) & \\mbox{if } j = k \\\\ \n",
    "                  \\frac{p_{kt}}{s_{jt}} \\int \\alpha_i s_{ijt} s_{ikt} dP_D(D) dP_\\nu(\\nu) & \\mbox{if } j \\neq k  \\end{array} \\right. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation\n",
    "### Overview\n",
    "\n",
    "The first thing one might try is a simple non-linear least squares to match observed shares: \n",
    "\n",
    "$$\\min_\\theta || s(x, p, \\delta(x, p, \\xi,; \\theta_1); \\theta_2) - S|| $$\n",
    "\n",
    "* First big problem is $\\xi$, we haven't put a distributional assumption\n",
    "on that though we could. \n",
    "* But then we'd run into the issue that $p$ is in principle correlated\n",
    "with $\\xi$. How? We'd need a supply side and more assumptions. \n",
    "* Also ALL of the parameters enter this optimization non-linearly, as\n",
    "opposed to just $\\theta_2$ in the method we will use. \n",
    "\n",
    "Instead, we use the following approach proposed by Berry(1994). We assume we have instruments\n",
    "which are uncorrelated with the structural error such that \n",
    "\n",
    "$$ E[Z\\xi(\\theta^*)] = 0 $$\n",
    "\n",
    "Where $\\xi(\\theta^*)$ is the implied structural error computed for the\n",
    "true value of $\\theta$. (I.e., $\\xi$ is the true structural error.)  The\n",
    "important thing is this is a linear moment condition, thought\n",
    "$\\xi(\\theta^*)$ must be computed nonlinearly. \n",
    "\n",
    "This leads to the following method:\n",
    "\n",
    "**Step 1**: Fix $\\theta_2$, there is a 1-to-1 mapping from shares to mean\n",
    "utilities, so solve the non-linear equation $S - s(x, p, \\delta;\n",
    "\\theta_2)$ for $\\delta$.\n",
    "\n",
    "**Step 2**: Now we have the equation, $\\delta_{jt}(\\theta_2) = x_{jt}\\beta - \\alpha p_{jt} +\n",
    "\\xi_{jt}$, a linear IV regression can be used to determine\n",
    "$\\xi_{jt}(\\theta_2)$.\n",
    "\n",
    "**Step 3**:  Search over $\\theta_2$ to minimize the GMM objective: \n",
    "\n",
    "$$ \\min_{\\theta_2} \\xi(\\theta_2)'Z\\Omega Z' \\xi(\\theta_2), $$ \n",
    "where $\\Omega$ is the variance covariance matrix $\\mathbf{E}[\\xi(\\theta_2)\\xi'(\\theta_2)]$.\n",
    "\n",
    "### Computing Market Shares\n",
    "\n",
    "We first need a way to compute $s(x, p, \\delta; \\theta_2)$. This is\n",
    "essentially an applciation of numerical integration. \n",
    "\n",
    "Let $S$ be the number of nodes we draw from the joint distribution of\n",
    "tastes and heterogeneity. That is we draw $\\left\\{ (\\nu_i, D_i)\n",
    "\\right\\}_{i=1}^S$. If we are using quadrature, we have weights $w_i$. \n",
    "\n",
    "$$ s(x, p, \\delta, P_{ns}; \\theta_2) = \\sum_{i = 1}^S w_i\n",
    "\\frac{\\exp \\left\\{ \\delta_{jt} + [-p_{jt}, x_{jt}](\\Pi D_i + \\Sigma v_i) \\right\\} }\n",
    "{ 1 + \\sum_{\\ell \\in J_t} \\exp \\left\\{ \\delta_{\\ell t} + [-p_{\\ell t}, x_{\\ell t}](\\Pi D_i + \\Sigma v_i) \\right\\}} $$\n",
    "\n",
    "This is a straightforward calculation, but we do have to think about\n",
    "overflow/underflow issues since we are exponentiating. Overflow is the\n",
    "more likely problem, and can be dealt with by just normalizing by the\n",
    "maximum indirect utility. \n",
    "\n",
    "$$ \\frac{ \\exp(a + b)}{1 + \\exp(a + b)} = \\frac{ \\exp(a)}{\\exp(-b) +\n",
    "\\exp(a)} $$\n",
    "\n",
    "So we can usually keep all the utilities in the computable range. Here is\n",
    "a look at conlon's share calculation, utlity normalization is actually\n",
    "commented out. \n",
    "\n",
    "```\n",
    "function [pjt,pijt]=rc_share_safe(delta, params,draws,mkt)\n",
    "% This gives the RC choice probabilities after integration (pjt)\n",
    "% Also gives the individual choice probabilities (pijt) for derivatives\n",
    "%\n",
    "% This function should be re-written in mex/C++ for improved speed\n",
    "    [ns k] = size(draws.v);\n",
    "    u1 = repmat(delta,[1 ns]) + mkt.x2*params.betai';\n",
    "    utils = exp(u1);\n",
    "    pijt = bsxfun(@rdivide,utils,1+sum(utils));\n",
    "    pjt=pijt*draws.w;\n",
    "    \n",
    "% under/overflow safety\n",
    "% should write an under/overflow safe version of this function\n",
    "%    m = max(u1); \n",
    "%    utils = exp(bsxfun(@minus,u1,m));\n",
    "%    pijt = bsxfun(@rdivide,utils,exp(-m)+sum(utils));\n",
    "\n",
    "end\n",
    "```\n",
    "\n",
    "### Inverting Market Shares to Mean Utilities\n",
    "Next, we need to be able to solve the inversion of shares to mean\n",
    "utilities. So we have find $\\delta$ to solve the nonlinear equation\n",
    "\n",
    "$$ S - s(x, p, \\delta; \\theta_2) = 0 $$\n",
    "\n",
    "This must be done once for each candidate parameter vector during\n",
    "estimation. On the bright side, it can be parallelized to be computed\n",
    "market by market. \n",
    "\n",
    "BLP note that this problem can be solved using using a contraction:\n",
    "\n",
    "$$ \\delta_{\\cdot t}^{h+1} = \\delta_{\\cdot t}^{h} + \\log S_{\\cdot t} - \\log\n",
    "s_{\\cdot t}(x_{\\cdot t}, p_{\\cdot t}, \\delta_{\\cdot t}^h; \\theta_2) $$\n",
    "\n",
    "If we have a good start point for $\\delta$, it can also be solved using\n",
    "Newton's method. \n",
    "\n",
    "People have been staring at this problem for some time. Recently\n",
    "Reynaerts, Varadhan and Nash (2012), proposed an acceleration based on a\n",
    "squared polynomial extrapolation of the draws (SQUAREM)\n",
    "It remains globally convergent (an issue with Newton's method \n",
    "while being 5 times faster than the \"traditional\" contraction. It is\n",
    "Conlon's preferred implementation. \n",
    "\n",
    "This code shows parallelization by market, and the various options for\n",
    "solving the fixed point: \n",
    "\n",
    "```\n",
    "function [ delta,Jac ] = solveAllShares(dtable,draws,params,method)\n",
    "%solveAllShares: Solve shares for delta market by market\n",
    "%   Can also return the Jacobian (d delta/ d theta)\n",
    "% \n",
    "% Everything in this routine should be re-written in mex/C++ for speed\n",
    "\n",
    "% newton's method or fixed-point iteration\n",
    "if(strcmp(method,'newton')),    \n",
    "    %parfor i =1:max(dtable.mktid),  %Dropping parallel so I can add\n",
    "    %breakpoints for teaching...\n",
    "    for i =1:max(dtable.mktid),\n",
    "        mkt_i    = dtable(dtable.mktid==i,:);\n",
    "        dhat=solveNewton(mkt_i.delta,params,draws,mkt_i);\n",
    "        % this returns the Jacobian once after convergence (for the\n",
    "        % gradient computation)\n",
    "        deltahat{i}=dhat;\n",
    "        Jacpart{i}=RCBLP_Jacobian(params,draws,mkt_i,'sterr');\n",
    "    end\n",
    "\n",
    "elseif(strcmp(method,'fixed-point')),\n",
    "    %parfor i =1:max(dtable.mktid),  %Dropping parallel so I can add\n",
    "    %breakpoints for teaching...\n",
    "    for i =1:max(dtable.mktid),\n",
    "        mkt_i    = dtable(dtable.mktid==i,:);\n",
    "        % don't start with bad values!\n",
    "        if sum(~isfinite(mkt_i.delta)) > 0\n",
    "            mkt_i.delta = log(mkt_i.sjt)-log(mkt_i.s0t);\n",
    "        end\n",
    "        % This is the BLP fixed point relation as a function handle\n",
    "        f=@(x)(x + log(mkt_i.sjt) - log(rc_share_safe(x,params,draws,mkt_i)));\n",
    "        % Call the SQUAREM routine of (Raeynerts, Varadayan and Nash)\n",
    "        [dhat]=fp_squarem(f,mkt_i.delta,'algorithm','squarem');\n",
    "        deltahat{i}=dhat;\n",
    "        % this returns the Jacobian once after convergence (for the\n",
    "        % gradient computation)\n",
    "        Jacpart{i}=RCBLP_Jacobian(params,draws,mkt_i,'sterr');\n",
    "    end\n",
    "end\n",
    "% pull deltas and jacobian out of market by market cell arrays\n",
    "% This way we dont need fixed # of products per market\n",
    "delta=real(cat(1,deltahat{:}));\n",
    "Jac=real(cat(1,Jacpart{:}));\n",
    "    \n",
    "end\n",
    "\n",
    "```\n",
    "\n",
    "And this function shows the two contraction methods:\n",
    "`blp-conlon/fp_squarem.m`. It is written as a generic contraction\n",
    "accelerator. Hence we pass the BLP contraction as an argument.\n",
    "\n",
    "Notice that this code also computes the Jacobian of the mean utility\n",
    "vector with respect to parameters, we'll see later where this is useful.\n",
    "\n",
    "### IV Regressions of Mean Utilities to Recover Unobserved Quality\n",
    "Now for a given $\\theta_2$ we know how to determine $\\delta(\\theta_2)$,\n",
    "the beauty of this is that now we can recover $\\xi(\\theta_2)$ as the\n",
    "residual of a linear IV regression: \n",
    "\n",
    "$$ \\delta_{jt}(\\theta_2) = x_{jt} \\beta - \\alpha p_{jt} + \\xi_{jt}(\\theta_2) $$\n",
    "\n",
    "Where the instrument set $z_{jt} = (x_{jt}, \\tilde{z}_{jt})$ where\n",
    "$\\tilde{z}_{jt}$ is a vector of valid instruments.  Note that we need\n",
    "enough instruments to identify ALL parameters in the model:\n",
    "\n",
    "* The $x_{jt}$ instruments provide moments to identify the $\\beta$\n",
    "coefficients. \n",
    "* One valid instrument for price will identify $\\alpha$. \n",
    "* If this IV regression is just identified, our GMM objective function\n",
    "will be 0, what is left to identify $\\theta_2 = (\\Pi, \\Sigma)$? Need\n",
    "additional instruments to identify these parameters. \n",
    "\n",
    "Since this is a computational course, we'll just assume such instruments\n",
    "exist. Finding them is a big part of doing reasonable empirical work. \n",
    "\n",
    "Conlon's IV regression is quite straightforward, just need to call |[beta,resid]=ivregression(delta,X,Z,W);|: \n",
    "\n",
    "```\n",
    " function [beta,resid]=ivregression(Y,X,Z,W)\n",
    "        if nargin <4\n",
    "            W = (Z'*Z) \\ eye(size(Z,2));\n",
    "        end\n",
    "        beta=(X'*Z * W * Z'*X)\\(X'*Z * W * Z'*Y);\n",
    "        if nargout >1\n",
    "            resid=Y-X * beta;\n",
    "        end\n",
    " end\n",
    "\n",
    "```\n",
    "\n",
    "You could save yourself solving a linear equation every iteration by\n",
    "computing the projection matrix and turning this into a matrix\n",
    "multiplication, but this isn't the time sink of the algorithm (solving\n",
    "for delta is) and this is a bit more intuitive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing GMM Objective\n",
    "Now we've got everything we need to compute the GMM Objective function,\n",
    "which is just a matrix multiplicaiton. \n",
    "\n",
    "\n",
    "```\n",
    "  function [fval,g]=evalSingle(theta)\n",
    "    % this extracts the parameters for your specification\n",
    "    p = get_params(theta,draws);\n",
    "    [delta,Jac]=solveAllShares(dtable,draws,p,method);\n",
    "    dtable.delta=delta;\n",
    "    [beta,resid]=ivregression(delta,X,Z,W);\n",
    "    fval=(resid'*Z)*W*(resid'*Z)';\n",
    "    g=-2*(Jac'*Z)*W*(resid'*Z)';\n",
    "  end\n",
    "\n",
    "\n",
    "```\n",
    "Where are $|X|, |Z|, |W|, |draws|$, and $|dtable|$ coming from? \n",
    "\n",
    "This code is using nested functions, so when we look at\n",
    "`solveRCBLPpar(dtable,draws,theta0,extract_fun)` you will see that |evalSingle|\n",
    "is defined inside, and so  inherits its scope. It is\n",
    "a nice trick to keep things clean. \n",
    "\n",
    "### Optimization and Two-Step GMM\n",
    "\n",
    "Once we have the objective function (and its Jacobian), we just need to\n",
    "use an optimizer to solve it. \n",
    "\n",
    "* The code is set up to use either |fmincon| or |knitromatlab|. \n",
    "\n",
    ">__Notice__: As we discussed in the theory portion, optimization is only\n",
    "over nonlinear parameters, so we use those to recover the nonlinear\n",
    "parameters post-Optimization. \n",
    "\n",
    "Here is the code for optimizing the GMM object:\n",
    "```  \n",
    "  function [res]=get_results(tableA,x0)\n",
    "   % function handle f is mapped to evalsingle below for a (X,Z,W) \n",
    "   if 0 %KNTRO license currently down, %exist('knitromatlab'),\n",
    "       [that]=knitromatlab(f,x0,[],[],[],[],lb,ub,[],[],ops);\n",
    "    else,\n",
    "       [that]=fmincon(f,x0,[],[],[],[],lb,ub,[],ops);\n",
    "    end\n",
    "    %\n",
    "    % After optimization recover the linear parameters and objective \n",
    "    thetahat =get_params(that,draws);\n",
    "    delta=solveAllShares(tableA,draws,thetahat,method);\n",
    "    dtable.delta=delta;\n",
    "    [beta,resid]=ivregression(delta,X,Z,W);\n",
    "    fval=(resid'*Z)*W*(resid'*Z)';\n",
    "    %\n",
    "    % Put the results into structure\n",
    "    [~,SEest]=getCovariance(that,dtable,draws);\n",
    "    res.fval = fval; res.beta=beta; res.theta = that; \n",
    "    res.delta=delta; res.resid = resid; res.SE=full(SEest);\n",
    "  end\n",
    "```\n",
    "Finally, since we have an overidentified GMM problem, we need to use the\n",
    "optimal weight matrix. Once we have a pilot estimate we can construct the\n",
    "optimal weight matrix\n",
    "\n",
    "$$ \\hat{W}_{opt} = (Z'\\hat{\\xi}\\hat{\\xi}'Z)^{-1} $$\n",
    "\n",
    "and optimize a second time. Any weight matrix is consistnent for the\n",
    "first stage, in practice we use $W_0 = (Z'Z)^{-1}$.\n",
    "\n",
    "The two-step procedure is the heart of `solveRCBLPpar.m` (par for parallel,\n",
    "though I have disabled that portion of the code). It is quite\n",
    "anti-climactic:\n",
    "\n",
    "```\n",
    "  tic\n",
    "  % first step\n",
    "  [results1]=get_results(dtable,theta0);\n",
    "  print_results(results1);\n",
    "  % update weight matrix and produce second-step\n",
    "  [W,~]=getCovariance(results1.theta,dtable,draws);\n",
    "  [results2]=get_results(dtable,results1.theta);\n",
    "  print_results(results2);\n",
    "  toc\n",
    "\n",
    "```\n",
    "And that's it! Now we are ready to take a stroll through the code. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab"
  },
  "language_info": {
   "codemirror_mode": "octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "matlab",
   "version": "0.16.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
